{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96ea765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, callbacks, regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adda4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167961ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 'v5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc532107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_schema.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "spectro_cols = config['spectro_cols']\n",
    "photo_cols = config['photometry_cols']\n",
    "generic_cols = config['generic_cols']\n",
    "target_col = config['target_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1774b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"data/processed/spectrometry_photometry.csv\")\n",
    "\n",
    "X = df[spectro_cols + photo_cols + generic_cols]\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c09897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9564109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Full_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " full_input (InputLayer)     [(None, 58)]              0         \n",
      "                                                                 \n",
      " Dense_128 (Dense)           (None, 128)               7552      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_256 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " Dense_64 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " logM_star (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,089\n",
      "Trainable params: 57,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First Model: Spectroscopic Features + Photometric Features\n",
    "full_input = keras.Input(shape=(X_train_scaled.shape[1]), name = 'full_input')\n",
    "x = layers.Dense(128, activation='relu', name='Dense_128')(full_input)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(256, activation='relu', name='Dense_256')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu', name='Dense_64')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "output = layers.Dense(1, name='logM_star')(x)\n",
    "\n",
    "full_model = keras.Model(inputs=full_input, outputs=output, name='Full_Model')\n",
    "full_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse', 'mape'])\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e381c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 2574256.5000 - mae: 592.8298 - mse: 2574256.5000 - mape: 2691.7375 - val_loss: 6709572.5000 - val_mae: 390.5462 - val_mse: 6709572.5000 - val_mape: 1162.7964\n",
      "Epoch 2/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 3115977.7500 - mae: 437.9362 - mse: 3115977.7500 - mape: 1726.6422 - val_loss: 5522454.0000 - val_mae: 324.5039 - val_mse: 5522454.0000 - val_mape: 932.6782\n",
      "Epoch 3/100\n",
      "3332/3332 [==============================] - 19s 6ms/step - loss: 2214738.0000 - mae: 333.9312 - mse: 2214738.0000 - mape: 1028.6436 - val_loss: 3332813.5000 - val_mae: 250.2531 - val_mse: 3332813.5000 - val_mape: 710.2819\n",
      "Epoch 4/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 1705590.1250 - mae: 279.8443 - mse: 1705590.1250 - mape: 774.4926 - val_loss: 1502256.6250 - val_mae: 215.6923 - val_mse: 1502256.6250 - val_mape: 692.7458\n",
      "Epoch 5/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 940337.7500 - mae: 247.9135 - mse: 940337.7500 - mape: 661.0020 - val_loss: 1372989.1250 - val_mae: 182.0876 - val_mse: 1372989.1250 - val_mape: 388.3400\n",
      "Epoch 6/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 765509.9375 - mae: 222.0131 - mse: 765509.9375 - mape: 572.6872 - val_loss: 887138.8750 - val_mae: 148.2343 - val_mse: 887138.8750 - val_mape: 504.2502\n",
      "Epoch 7/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 690875.5625 - mae: 198.2712 - mse: 690875.5625 - mape: 498.9778 - val_loss: 665260.6250 - val_mae: 131.6237 - val_mse: 665260.6250 - val_mape: 536.6802\n",
      "Epoch 8/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 572022.9375 - mae: 185.8754 - mse: 572022.9375 - mape: 460.1983 - val_loss: 579414.1875 - val_mae: 120.3155 - val_mse: 579414.1875 - val_mape: 432.5679\n",
      "Epoch 9/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 526518.9375 - mae: 170.3421 - mse: 526518.9375 - mape: 382.4883 - val_loss: 561603.6250 - val_mae: 123.2627 - val_mse: 561603.6250 - val_mape: 354.2741\n",
      "Epoch 10/100\n",
      "3332/3332 [==============================] - 23s 7ms/step - loss: 501040.2188 - mae: 163.8329 - mse: 501040.2188 - mape: 368.1136 - val_loss: 1273615.5000 - val_mae: 106.7591 - val_mse: 1273615.5000 - val_mape: 411.1213\n",
      "Epoch 11/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 502796.1250 - mae: 161.7272 - mse: 502796.1250 - mape: 367.5089 - val_loss: 788019.2500 - val_mae: 124.7901 - val_mse: 788019.2500 - val_mape: 551.5128\n",
      "Epoch 12/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 477098.3438 - mae: 157.3209 - mse: 477098.3438 - mape: 364.1423 - val_loss: 635909.5000 - val_mae: 99.6325 - val_mse: 635909.5000 - val_mape: 236.5065\n",
      "Epoch 13/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 473350.4375 - mae: 159.6210 - mse: 473350.4375 - mape: 374.6426 - val_loss: 1060893.2500 - val_mae: 98.4654 - val_mse: 1060893.2500 - val_mape: 401.7805\n",
      "Epoch 14/100\n",
      "3332/3332 [==============================] - 23s 7ms/step - loss: 465144.3125 - mae: 154.8095 - mse: 465144.3125 - mape: 356.7647 - val_loss: 752449.0000 - val_mae: 97.8183 - val_mse: 752449.0000 - val_mape: 369.5435\n",
      "Epoch 15/100\n",
      "3332/3332 [==============================] - 25s 8ms/step - loss: 468887.3438 - mae: 152.4262 - mse: 468887.3438 - mape: 339.1629 - val_loss: 725435.3750 - val_mae: 82.7711 - val_mse: 725435.3750 - val_mape: 288.9483\n",
      "Epoch 16/100\n",
      "3332/3332 [==============================] - 25s 8ms/step - loss: 433827.7500 - mae: 148.7034 - mse: 433827.7500 - mape: 322.1735 - val_loss: 780428.1250 - val_mae: 92.6508 - val_mse: 780428.1250 - val_mape: 372.1304\n",
      "Epoch 17/100\n",
      "3332/3332 [==============================] - 25s 8ms/step - loss: 443168.4375 - mae: 149.2390 - mse: 443168.4375 - mape: 328.6129 - val_loss: 1169084.3750 - val_mae: 108.3503 - val_mse: 1169084.3750 - val_mape: 385.5800\n",
      "Epoch 18/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 424916.3438 - mae: 150.9483 - mse: 424916.3438 - mape: 357.3317 - val_loss: 1207504.0000 - val_mae: 86.9010 - val_mse: 1207504.0000 - val_mape: 293.1848\n",
      "Epoch 19/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 436570.5938 - mae: 151.3552 - mse: 436570.5938 - mape: 364.4969 - val_loss: 924854.4375 - val_mae: 79.1978 - val_mse: 924854.4375 - val_mape: 261.0696\n",
      "Epoch 20/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 437551.2188 - mae: 147.0174 - mse: 437551.2188 - mape: 319.6339 - val_loss: 618711.1875 - val_mae: 82.5083 - val_mse: 618711.1875 - val_mape: 321.7023\n",
      "Epoch 21/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 400177.8438 - mae: 139.7557 - mse: 400177.8438 - mape: 292.9249 - val_loss: 923855.3125 - val_mae: 103.6653 - val_mse: 923855.3125 - val_mape: 251.9996\n",
      "Epoch 22/100\n",
      "3332/3332 [==============================] - 20s 6ms/step - loss: 398044.5625 - mae: 141.2812 - mse: 398044.5625 - mape: 307.8556 - val_loss: 1142237.7500 - val_mae: 87.0973 - val_mse: 1142237.7500 - val_mape: 372.9656\n",
      "Epoch 23/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 408601.5625 - mae: 145.1136 - mse: 408601.5625 - mape: 320.8402 - val_loss: 1077181.0000 - val_mae: 79.6159 - val_mse: 1077181.0000 - val_mape: 273.1679\n",
      "Epoch 24/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 401595.0938 - mae: 142.5772 - mse: 401595.0938 - mape: 311.6106 - val_loss: 1177863.5000 - val_mae: 104.6377 - val_mse: 1177863.5000 - val_mape: 390.0642\n",
      "Epoch 25/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 1720544.0000 - mae: 145.4907 - mse: 1720544.0000 - mape: 291.2332 - val_loss: 1375926.2500 - val_mae: 81.0114 - val_mse: 1375926.2500 - val_mape: 358.5054\n",
      "Epoch 26/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 394376.5312 - mae: 139.1158 - mse: 394376.5312 - mape: 296.5709 - val_loss: 762190.4375 - val_mae: 81.8355 - val_mse: 762190.4375 - val_mape: 252.8206\n",
      "Epoch 27/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 397344.3125 - mae: 138.9887 - mse: 397344.3125 - mape: 291.8332 - val_loss: 738822.1250 - val_mae: 73.8735 - val_mse: 738822.1250 - val_mape: 158.7953\n",
      "Epoch 28/100\n",
      "3332/3332 [==============================] - 21s 6ms/step - loss: 379819.7500 - mae: 139.5053 - mse: 379819.7500 - mape: 305.4301 - val_loss: 905642.8125 - val_mae: 89.2072 - val_mse: 905642.8125 - val_mape: 252.8751\n",
      "Epoch 29/100\n",
      "3332/3332 [==============================] - 22s 7ms/step - loss: 387613.1250 - mae: 136.4298 - mse: 387613.1250 - mape: 281.9521 - val_loss: 649943.6250 - val_mae: 91.6578 - val_mse: 649943.6250 - val_mape: 280.2975\n",
      "Epoch 30/100\n",
      "3332/3332 [==============================] - 26s 8ms/step - loss: 374872.2500 - mae: 134.5755 - mse: 374872.2500 - mape: 274.8501 - val_loss: 1490542.1250 - val_mae: 98.2281 - val_mse: 1490542.1250 - val_mape: 394.8639\n",
      "Epoch 31/100\n",
      "3332/3332 [==============================] - 31s 9ms/step - loss: 458995.6562 - mae: 137.2700 - mse: 458995.6562 - mape: 293.1796 - val_loss: 852306.3750 - val_mae: 79.0336 - val_mse: 852306.3750 - val_mape: 198.1189\n",
      "Epoch 32/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 363857.3125 - mae: 132.7615 - mse: 363857.3125 - mape: 270.2010 - val_loss: 970877.0625 - val_mae: 68.9787 - val_mse: 970877.0625 - val_mape: 141.4042\n",
      "Epoch 33/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 390938.6562 - mae: 135.1371 - mse: 390938.6562 - mape: 273.6140 - val_loss: 719023.8125 - val_mae: 77.7311 - val_mse: 719023.8125 - val_mape: 319.1093\n",
      "Epoch 34/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 388218.3438 - mae: 134.8632 - mse: 388218.3438 - mape: 285.2509 - val_loss: 597682.7500 - val_mae: 83.8882 - val_mse: 597682.7500 - val_mape: 289.9845\n",
      "Epoch 35/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 362168.1875 - mae: 132.9970 - mse: 362168.1875 - mape: 276.0703 - val_loss: 719108.1250 - val_mae: 86.6639 - val_mse: 719108.1250 - val_mape: 122.2728\n",
      "Epoch 36/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 364227.7500 - mae: 132.3819 - mse: 364227.7500 - mape: 268.0480 - val_loss: 591690.5625 - val_mae: 127.4807 - val_mse: 591690.5625 - val_mape: 153.3954\n",
      "Epoch 37/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 371786.6562 - mae: 132.3588 - mse: 371786.6562 - mape: 279.8043 - val_loss: 781384.9375 - val_mae: 78.9527 - val_mse: 781384.9375 - val_mape: 370.3270\n",
      "Epoch 38/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 3751054.7500 - mae: 138.1326 - mse: 3751054.7500 - mape: 275.8092 - val_loss: 518786.3125 - val_mae: 81.7841 - val_mse: 518786.3125 - val_mape: 284.3201\n",
      "Epoch 39/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 353047.4062 - mae: 130.2190 - mse: 353047.4062 - mape: 264.3962 - val_loss: 829309.5000 - val_mae: 80.4043 - val_mse: 829309.5000 - val_mape: 287.4802\n",
      "Epoch 40/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 334358.3750 - mae: 127.6107 - mse: 334358.3750 - mape: 260.3628 - val_loss: 1047004.2500 - val_mae: 82.9300 - val_mse: 1047004.2500 - val_mape: 245.4337\n",
      "Epoch 41/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 784523.8750 - mae: 136.6977 - mse: 784523.8750 - mape: 295.0223 - val_loss: 377953.0000 - val_mae: 79.8511 - val_mse: 377953.0000 - val_mape: 197.8690\n",
      "Epoch 42/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 345567.8438 - mae: 130.4970 - mse: 345567.8438 - mape: 278.6176 - val_loss: 545507.5000 - val_mae: 64.3294 - val_mse: 545507.5000 - val_mape: 194.7629\n",
      "Epoch 43/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 347449.3438 - mae: 129.7778 - mse: 347449.3438 - mape: 274.0043 - val_loss: 510146.3750 - val_mae: 61.6776 - val_mse: 510146.3750 - val_mape: 191.2889\n",
      "Epoch 44/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 356754.9375 - mae: 130.5696 - mse: 356754.9375 - mape: 266.4371 - val_loss: 730565.6250 - val_mae: 97.7764 - val_mse: 730565.6250 - val_mape: 161.8600\n",
      "Epoch 45/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 345855.2812 - mae: 127.4988 - mse: 345855.2812 - mape: 258.1922 - val_loss: 569290.5000 - val_mae: 90.8209 - val_mse: 569290.5000 - val_mape: 246.5371\n",
      "Epoch 46/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 347744.2812 - mae: 128.6334 - mse: 347744.2812 - mape: 266.2627 - val_loss: 522096.6875 - val_mae: 69.4983 - val_mse: 522096.6875 - val_mape: 223.6573\n",
      "Epoch 47/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 4239143.5000 - mae: 135.7902 - mse: 4239143.5000 - mape: 270.7402 - val_loss: 484241.1875 - val_mae: 75.8969 - val_mse: 484241.1875 - val_mape: 311.3228\n",
      "Epoch 48/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 329566.4062 - mae: 125.8663 - mse: 329566.4062 - mape: 256.5562 - val_loss: 657135.5000 - val_mae: 76.8717 - val_mse: 657135.5000 - val_mape: 286.2617\n",
      "Epoch 49/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 341078.4062 - mae: 126.7790 - mse: 341078.4062 - mape: 264.8807 - val_loss: 386550.1875 - val_mae: 67.7607 - val_mse: 386550.1875 - val_mape: 200.1068\n",
      "Epoch 50/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 338901.5938 - mae: 126.5770 - mse: 338901.5938 - mape: 266.7633 - val_loss: 321736.6250 - val_mae: 84.0123 - val_mse: 321736.6250 - val_mape: 279.5133\n",
      "Epoch 51/100\n",
      "3332/3332 [==============================] - 27s 8ms/step - loss: 329651.1562 - mae: 125.1846 - mse: 329651.1562 - mape: 253.1239 - val_loss: 371488.5625 - val_mae: 61.4035 - val_mse: 371488.5625 - val_mape: 154.4945\n",
      "Epoch 52/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 335846.8125 - mae: 128.2418 - mse: 335846.8125 - mape: 275.8497 - val_loss: 522068.7188 - val_mae: 67.9713 - val_mse: 522068.7188 - val_mape: 325.3244\n",
      "Epoch 53/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 332196.6875 - mae: 126.8045 - mse: 332196.6875 - mape: 276.9419 - val_loss: 382012.5312 - val_mae: 66.6115 - val_mse: 382012.5312 - val_mape: 292.5312\n",
      "Epoch 54/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 324484.7812 - mae: 125.6983 - mse: 324484.7812 - mape: 286.3902 - val_loss: 297881.9375 - val_mae: 61.5387 - val_mse: 297881.9375 - val_mape: 207.4260\n",
      "Epoch 55/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 442889.8750 - mae: 125.2723 - mse: 442889.8750 - mape: 270.7313 - val_loss: 482271.3125 - val_mae: 83.5084 - val_mse: 482271.3125 - val_mape: 286.4103\n",
      "Epoch 56/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 313924.8750 - mae: 122.2728 - mse: 313924.8750 - mape: 262.6752 - val_loss: 435554.9062 - val_mae: 73.0360 - val_mse: 435554.9062 - val_mape: 294.4732\n",
      "Epoch 57/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 306277.3125 - mae: 119.3953 - mse: 306277.3125 - mape: 249.1572 - val_loss: 361961.9688 - val_mae: 64.2694 - val_mse: 361961.9688 - val_mape: 278.5108\n",
      "Epoch 58/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 312987.0625 - mae: 120.0493 - mse: 312987.0625 - mape: 263.6214 - val_loss: 385660.4062 - val_mae: 69.3606 - val_mse: 385660.4062 - val_mape: 297.8534\n",
      "Epoch 59/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 317794.0938 - mae: 120.9164 - mse: 317794.0938 - mape: 262.3042 - val_loss: 387706.1875 - val_mae: 69.3713 - val_mse: 387706.1875 - val_mape: 329.8433\n",
      "Epoch 60/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 353864.1875 - mae: 121.8783 - mse: 353864.1875 - mape: 272.8582 - val_loss: 373955.9062 - val_mae: 93.7464 - val_mse: 373955.9062 - val_mape: 268.1383\n",
      "Epoch 61/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 307621.4062 - mae: 118.8592 - mse: 307621.4062 - mape: 257.5989 - val_loss: 301273.9375 - val_mae: 68.9243 - val_mse: 301273.9375 - val_mape: 237.3108\n",
      "Epoch 62/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 1333722.1250 - mae: 122.4186 - mse: 1333722.1250 - mape: 253.1774 - val_loss: 332870.9062 - val_mae: 66.7059 - val_mse: 332870.9062 - val_mape: 257.5417\n",
      "Epoch 63/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 299692.7188 - mae: 117.8738 - mse: 299692.7188 - mape: 256.4128 - val_loss: 268307.1562 - val_mae: 87.9161 - val_mse: 268307.1562 - val_mape: 243.6982\n",
      "Epoch 64/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 301645.2188 - mae: 117.5772 - mse: 301645.2188 - mape: 255.0168 - val_loss: 392866.7812 - val_mae: 61.3572 - val_mse: 392866.7812 - val_mape: 213.7304\n",
      "Epoch 65/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 423079.8750 - mae: 117.6480 - mse: 423079.8750 - mape: 253.9644 - val_loss: 337852.4375 - val_mae: 71.3074 - val_mse: 337852.4375 - val_mape: 123.3398\n",
      "Epoch 66/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 305118.1562 - mae: 117.4432 - mse: 305118.1562 - mape: 249.1974 - val_loss: 286048.7188 - val_mae: 86.4449 - val_mse: 286048.7188 - val_mape: 203.1203\n",
      "Epoch 67/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 308231.5625 - mae: 117.2214 - mse: 308231.5625 - mape: 248.5041 - val_loss: 364834.3750 - val_mae: 59.9268 - val_mse: 364834.3750 - val_mape: 164.7545\n",
      "Epoch 68/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 305510.4688 - mae: 117.4679 - mse: 305510.4688 - mape: 254.9477 - val_loss: 368803.8125 - val_mae: 92.8770 - val_mse: 368803.8125 - val_mape: 372.9333\n",
      "Epoch 69/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 309168.1250 - mae: 116.2341 - mse: 309168.1250 - mape: 258.1530 - val_loss: 515336.7500 - val_mae: 91.3461 - val_mse: 515336.7500 - val_mape: 311.2788\n",
      "Epoch 70/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 296197.0000 - mae: 114.9560 - mse: 296197.0000 - mape: 248.9493 - val_loss: 405535.0938 - val_mae: 58.3045 - val_mse: 405535.0938 - val_mape: 273.3841\n",
      "Epoch 71/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 522993.1250 - mae: 116.2298 - mse: 522993.1250 - mape: 263.1838 - val_loss: 335405.1875 - val_mae: 60.8767 - val_mse: 335405.1875 - val_mape: 200.1123\n",
      "Epoch 72/100\n",
      "3332/3332 [==============================] - 28s 8ms/step - loss: 297344.1250 - mae: 114.7563 - mse: 297344.1250 - mape: 250.7176 - val_loss: 448731.3750 - val_mae: 67.4430 - val_mse: 448731.3750 - val_mape: 244.3420\n",
      "Epoch 73/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 276063.8750 - mae: 113.1908 - mse: 276063.8750 - mape: 249.9269 - val_loss: 443015.6562 - val_mae: 70.1252 - val_mse: 443015.6562 - val_mape: 355.1901\n",
      "Epoch 74/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 356765.0000 - mae: 114.8352 - mse: 356765.0000 - mape: 243.7897 - val_loss: 478167.2500 - val_mae: 71.6854 - val_mse: 478167.2500 - val_mape: 424.7448\n",
      "Epoch 75/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 289997.0000 - mae: 114.2287 - mse: 289997.0000 - mape: 257.1962 - val_loss: 430102.4375 - val_mae: 68.8886 - val_mse: 430102.4375 - val_mape: 265.8016\n",
      "Epoch 76/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 291047.4375 - mae: 114.0953 - mse: 291047.4375 - mape: 250.8785 - val_loss: 436087.4062 - val_mae: 66.2605 - val_mse: 436087.4062 - val_mape: 299.2181\n",
      "Epoch 77/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 281275.6250 - mae: 112.5186 - mse: 281275.6250 - mape: 249.2562 - val_loss: 473975.1562 - val_mae: 68.5491 - val_mse: 473975.1562 - val_mape: 303.2587\n",
      "Epoch 78/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 295131.8438 - mae: 115.1892 - mse: 295131.8438 - mape: 268.1029 - val_loss: 392413.7500 - val_mae: 74.3050 - val_mse: 392413.7500 - val_mape: 299.2987\n",
      "Epoch 79/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 424351.8438 - mae: 114.7296 - mse: 424351.8438 - mape: 267.9560 - val_loss: 495992.6875 - val_mae: 74.9918 - val_mse: 495992.6875 - val_mape: 319.3870\n",
      "Epoch 80/100\n",
      "3332/3332 [==============================] - 28s 9ms/step - loss: 287496.1875 - mae: 115.5232 - mse: 287496.1875 - mape: 276.4667 - val_loss: 453404.1250 - val_mae: 58.9436 - val_mse: 453404.1250 - val_mape: 270.5355\n",
      "Epoch 81/100\n",
      "3332/3332 [==============================] - 31s 9ms/step - loss: 284548.6875 - mae: 113.2098 - mse: 284548.6875 - mape: 264.4188 - val_loss: 320415.7500 - val_mae: 66.7811 - val_mse: 320415.7500 - val_mape: 271.6442\n",
      "Epoch 82/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 294767.4688 - mae: 113.5174 - mse: 294767.4688 - mape: 272.8409 - val_loss: 308124.6562 - val_mae: 54.3436 - val_mse: 308124.6562 - val_mape: 254.8304\n",
      "Epoch 83/100\n",
      "3332/3332 [==============================] - 31s 9ms/step - loss: 269260.5000 - mae: 111.6547 - mse: 269260.5000 - mape: 257.4100 - val_loss: 379737.1875 - val_mae: 61.0141 - val_mse: 379737.1875 - val_mape: 209.3700\n",
      "Epoch 84/100\n",
      "3332/3332 [==============================] - 31s 9ms/step - loss: 254435.3594 - mae: 110.1994 - mse: 254435.3594 - mape: 252.8995 - val_loss: 423109.0000 - val_mae: 81.0222 - val_mse: 423109.0000 - val_mape: 446.5668\n",
      "Epoch 85/100\n",
      "3332/3332 [==============================] - 30s 9ms/step - loss: 264708.8438 - mae: 111.4326 - mse: 264708.8438 - mape: 271.9772 - val_loss: 633777.8750 - val_mae: 57.2095 - val_mse: 633777.8750 - val_mape: 226.2936\n",
      "Epoch 86/100\n",
      "3332/3332 [==============================] - 29s 9ms/step - loss: 308302.4062 - mae: 110.8502 - mse: 308302.4062 - mape: 259.3370 - val_loss: 615701.7500 - val_mae: 71.9947 - val_mse: 615701.7500 - val_mape: 168.0826\n",
      "Epoch 87/100\n",
      "3332/3332 [==============================] - 22s 7ms/step - loss: 451857.0625 - mae: 113.2724 - mse: 451857.0625 - mape: 265.6482 - val_loss: 536861.1250 - val_mae: 71.2012 - val_mse: 536861.1250 - val_mape: 309.4447\n",
      "Epoch 88/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 283791.0625 - mae: 110.8069 - mse: 283791.0625 - mape: 251.9947 - val_loss: 432995.5312 - val_mae: 55.0697 - val_mse: 432995.5312 - val_mape: 247.4859\n",
      "Epoch 89/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 259739.8281 - mae: 108.7813 - mse: 259739.8281 - mape: 250.1472 - val_loss: 543533.8750 - val_mae: 61.8541 - val_mse: 543533.8750 - val_mape: 167.1546\n",
      "Epoch 90/100\n",
      "3332/3332 [==============================] - 24s 7ms/step - loss: 282808.3438 - mae: 110.5609 - mse: 282808.3438 - mape: 261.0801 - val_loss: 547242.3125 - val_mae: 61.6223 - val_mse: 547242.3125 - val_mape: 208.5432\n",
      "Epoch 91/100\n",
      "3332/3332 [==============================] - 39s 12ms/step - loss: 260777.5781 - mae: 108.9820 - mse: 260777.5781 - mape: 242.4396 - val_loss: 492651.8750 - val_mae: 57.8556 - val_mse: 492651.8750 - val_mape: 170.6748\n",
      "Epoch 92/100\n",
      "3332/3332 [==============================] - 46s 14ms/step - loss: 268104.5625 - mae: 110.2172 - mse: 268104.5625 - mape: 252.1340 - val_loss: 517344.5938 - val_mae: 56.7304 - val_mse: 517344.5938 - val_mape: 154.4844\n",
      "Epoch 93/100\n",
      "3332/3332 [==============================] - 46s 14ms/step - loss: 267004.7188 - mae: 108.9851 - mse: 267004.7188 - mape: 243.1151 - val_loss: 477897.9688 - val_mae: 57.2595 - val_mse: 477897.9688 - val_mape: 174.2157\n",
      "Epoch 94/100\n",
      "3332/3332 [==============================] - 47s 14ms/step - loss: 309634.8125 - mae: 108.8621 - mse: 309634.8125 - mape: 242.9659 - val_loss: 449288.9375 - val_mae: 55.2457 - val_mse: 449288.9375 - val_mape: 138.8867\n",
      "Epoch 95/100\n",
      "3332/3332 [==============================] - 46s 14ms/step - loss: 267629.6875 - mae: 109.0368 - mse: 267629.6875 - mape: 241.8571 - val_loss: 476011.0312 - val_mae: 55.7754 - val_mse: 476011.0312 - val_mape: 229.0165\n",
      "Epoch 96/100\n",
      "3332/3332 [==============================] - 46s 14ms/step - loss: 263987.5938 - mae: 109.2630 - mse: 263987.5938 - mape: 244.7361 - val_loss: 319983.3750 - val_mae: 52.8394 - val_mse: 319983.3750 - val_mape: 205.4113\n",
      "Epoch 97/100\n",
      "3332/3332 [==============================] - 45s 14ms/step - loss: 264260.8438 - mae: 109.4863 - mse: 264260.8438 - mape: 247.4192 - val_loss: 464534.8438 - val_mae: 52.1952 - val_mse: 464534.8438 - val_mape: 181.9556\n",
      "Epoch 98/100\n",
      "3332/3332 [==============================] - 45s 14ms/step - loss: 269196.0625 - mae: 108.9559 - mse: 269196.0625 - mape: 253.4005 - val_loss: 377961.1875 - val_mae: 79.9424 - val_mse: 377961.1875 - val_mape: 135.3702\n",
      "Epoch 99/100\n",
      "3332/3332 [==============================] - 43s 13ms/step - loss: 261355.5156 - mae: 108.5210 - mse: 261355.5156 - mape: 247.2996 - val_loss: 572042.8125 - val_mae: 77.5503 - val_mse: 572042.8125 - val_mape: 187.7557\n",
      "Epoch 100/100\n",
      "3332/3332 [==============================] - 36s 11ms/step - loss: 259602.0625 - mae: 107.7881 - mse: 259602.0625 - mape: 244.8832 - val_loss: 679522.8750 - val_mae: 66.0182 - val_mse: 679522.8750 - val_mape: 279.5784\n"
     ]
    }
   ],
   "source": [
    "history_full_model = full_model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f03bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2271d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units=32, dropout_rate=0.2, l2_reg=0.01, patience=10):\n",
    "    input_shape = X_train_scaled.shape[1]\n",
    "    \n",
    "    inputs = keras.Input(shape=(input_shape,))\n",
    "    \n",
    "    x = layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Dense(units * 2, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Dense(units * 4, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse', 'mape'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SavingKerasRegressor(KerasRegressor):\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # Extract current params\n",
    "        current_params = self.get_params()\n",
    "        \n",
    "        # Construct unique filename from current parameters\n",
    "        filename = \"spec_photo_v4.0_units{}_do{}_l2{}_bs{}_ep{}_pat{}.h5\".format(\n",
    "            current_params.get('units'),\n",
    "            current_params.get('dropout_rate'),\n",
    "            current_params.get('l2_reg'),\n",
    "            current_params.get('batch_size'),\n",
    "            current_params.get('epochs'),\n",
    "            current_params.get('patience'),\n",
    "            current_params.get('validation_split')\n",
    "        )\n",
    "        os.makedirs(f\"history/v4.0\", exist_ok=True)\n",
    "        model_path = os.path.join(\"models\", f\"model_{filename}.h5\")\n",
    "        history_path = os.path.join(\"history/v4.0\", f\"history_{filename}.json\")\n",
    "\n",
    "        # Callbacks\n",
    "        checkpoint_cb = ModelCheckpoint(\n",
    "            model_path,\n",
    "            save_best_only=True,\n",
    "            save_format='h5',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=0\n",
    "        )\n",
    "        early_cb = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Add callbacks and validation_split\n",
    "        kwargs['callbacks'] = [checkpoint_cb, early_cb]\n",
    "        kwargs['validation_split'] = current_params.get('validation_split')\n",
    "\n",
    "        history = super().fit(X, y, **kwargs)\n",
    "        \n",
    "        # Save history to JSON\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(history.history, f)\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e470d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\AppData\\Local\\Temp\\ipykernel_31424\\3959282293.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  regressor = SavingKerasRegressor(build_fn=build_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "regressor = SavingKerasRegressor(build_fn=build_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'units': [32, 64],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'l2_reg': [0.001, 0.01],\n",
    "    'patience': [20, 30],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [200],\n",
    "    'validation_split': [0.5, 0.6, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9da777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 8.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 8.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 6.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 6.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 3.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 3.2min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 6.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 8.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 8.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 4.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 5.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 3.2min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=12.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=11.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 6.2min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 3.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 6.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time=11.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 5.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 8.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 8.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 7.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 7.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 9.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 8.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 6.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 9.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time=10.2min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 3.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 6.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=14.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 7.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 4.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 8.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 4.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 5.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 4.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 6.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 5.2min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 5.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 4.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 6.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 6.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 7.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 8.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 3.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time=13.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time=10.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time=10.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 9.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time=10.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time=11.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time=12.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=11.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=11.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 7.3min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 3.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 7.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 7.6min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 5.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 6.5min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 8.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time=15.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 8.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 3.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 3.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time=11.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 7.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 6.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time=10.7min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 9.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=16.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 3.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time=11.9min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time=16.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 3.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 8.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 6.0min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 9.8min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 3.1min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 3.4min\n",
      "[CV] END batch_size=16, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time=13.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 4.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 3.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 3.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 5.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 9.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 7.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 2.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 7.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 8.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 2.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 3.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 3.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 2.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 5.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 2.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 3.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 7.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 3.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 5.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 3.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 7.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 7.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 2.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time= 5.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 2.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 3.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 4.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 1.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 6.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time=11.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 3.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 2.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 6.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time= 1.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time= 1.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time=  57.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time=  53.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time=  53.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time=  51.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time=  51.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time=  57.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time=  54.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time=  58.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time=  51.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 1.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=  57.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time=  54.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time=  54.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time=  51.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time=  51.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time=  57.0s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time=  54.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time=  54.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time=  51.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time=  51.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time=  56.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time=  54.0s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time=  54.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time=  51.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time=  51.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time=  57.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time=  54.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time=  59.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=  51.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=  51.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time=  56.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time=  57.0s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time=  54.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time=  54.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time=  50.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time= 1.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time=  57.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time=  54.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time=  54.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time=  51.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time=  52.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time=  56.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.5; total time=  56.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time=  54.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.6; total time=  54.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time=  51.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=32, validation_split=0.7; total time=  51.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time=  57.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.5; total time= 4.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time=  54.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.6; total time=  59.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time=  51.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=20, units=64, validation_split=0.7; total time= 5.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=  56.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.5; total time=  58.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time=  55.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.6; total time=  55.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time=  52.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=32, validation_split=0.7; total time=  52.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time=  58.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time=  55.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.6; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time=  52.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.001, patience=30, units=64, validation_split=0.7; total time=  53.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time=  57.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.5; total time=  58.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time=  54.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.6; total time=  55.2s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time=  51.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=32, validation_split=0.7; total time=  52.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time=  58.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time=  55.5s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.6; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=  53.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=20, units=64, validation_split=0.7; total time=  52.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time=  59.0s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time=  55.3s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.6; total time=  56.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time=  52.4s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=32, validation_split=0.7; total time=  52.1s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time=  58.7s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.5; total time= 1.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time=  55.8s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.6; total time=  55.9s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time=  52.6s\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=200, l2_reg=0.01, patience=30, units=64, validation_split=0.7; total time=  52.3s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=2, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f41bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  -549342.2775366982\n",
      "Best Params:  {'batch_size': 16, 'dropout_rate': 0.2, 'epochs': 200, 'l2_reg': 0.001, 'patience': 20, 'units': 32, 'validation_split': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", grid_result.best_score_)\n",
    "print(\"Best Params: \", grid_result.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
